{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Copy of pag_seq_lstm_cnn_attention_fm_mailru.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TosyIB8ZQzH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "colab_type": "code",
        "id": "J3vI12ATXMUc",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import json\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qf-wdNk_Fpx",
        "colab_type": "code",
        "outputId": "452f6e4e-b260-42f2-d29a-7057da83de55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3TJ7pw0OZ-I",
        "colab_type": "code",
        "outputId": "7726794e-71b9-41fa-b150-8280e42d7ec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd gdrive/'My Drive'/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcxfDb56WFdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('permutate_anw_ques.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNAUuVd7Q5JI",
        "colab_type": "code",
        "outputId": "cbe8c1be-e32e-4f58-a5b5-979784edb7fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%time\n",
        "from zipfile import ZipFile\n",
        "\n",
        "downloaded_train = drive.CreateFile({'id':'10qtOKBsGFQlZ6YzQxV30uHT7truULE1E'}) \n",
        "downloaded_train.GetContentFile('train.csv.zip')\n",
        "\n",
        "with ZipFile('train.csv.zip', 'r') as zipObj:\n",
        "   zipObj.extractall()\n",
        "\n",
        "down_main_cat_map = drive.CreateFile({'id': '1l70MFuRBb7IgaVn6hrx0_X3lU0_q0B7C'}) \n",
        "down_main_cat_map.GetContentFile('main_category_mapper.json')\n",
        "\n",
        "downloaded_unsupervised = drive.CreateFile({'id':'1vTeZFDl4ugkRv_6mUCl7gJk8DMnE8ECB'}) \n",
        "downloaded_unsupervised.GetContentFile('unsupervised.csv.zip')\n",
        "\n",
        "with ZipFile('unsupervised.csv.zip', 'r') as zipObj:\n",
        "   zipObj.extractall()\n",
        "\n",
        "down_sub_cat_map = drive.CreateFile({'id': '1SJhd1yLU2V6eKGKI_R7Gw0ybGC9RaxJu'}) \n",
        "down_sub_cat_map.GetContentFile('sub_category_mapper.json')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1 µs, sys: 1e+03 ns, total: 2 µs\n",
            "Wall time: 4.29 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "8VcdFVSGHxHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import json\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jXnIZ7SaHxHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMnIDWL_4gMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded_sub = drive.CreateFile({'id':'1QqoCIhAJlMxW5_TSaNnOUU08civyHWOP'}) \n",
        "downloaded_sub.GetContentFile('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlJwLkUeYOr2",
        "colab_type": "code",
        "outputId": "32600cd6-7025-4614-e59f-66d5c7a4fdfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test = pd.read_csv('test.csv')\n",
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Подскажите сайт российский, вещи заказывать: )...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Как заказать Рикардо Милоса в Москве?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Пустят ли меня в Израиль, если я работаю в ОАЭ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>почему о наличии пальмового масла и консервато...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Вот во всех бедах России винят правительство.....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                                           question\n",
              "0      0  Подскажите сайт российский, вещи заказывать: )...\n",
              "1      1              Как заказать Рикардо Милоса в Москве?\n",
              "2      2    Пустят ли меня в Израиль, если я работаю в ОАЭ?\n",
              "3      3  почему о наличии пальмового масла и консервато...\n",
              "4      4  Вот во всех бедах России винят правительство....."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z95k9xPSCj2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def filter_ru_en_words(x):\n",
        "  x = ' '.join(re.findall('[a-zа-яё0-9]+', x.lower()))\n",
        "  x = re.sub('[0-9]+', ' число ', x)\n",
        "  x = re.sub('ё', 'е', x)\n",
        "  x = re.sub('\\s+', ' ', x)\n",
        "  return x\n",
        "train['w_cl'] = train.question.apply(filter_ru_en_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozJg0-ZhKN9t",
        "colab_type": "code",
        "outputId": "43c3e6e6-bb41-49db-d4b3-f8d42d3ffd04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install pymorphy2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.6/dist-packages (0.8)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (2.4.393442.3710985)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oABU1BZ1KVxa",
        "colab_type": "code",
        "outputId": "12f68efc-315e-457a-c42d-90a18cfc3b4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pymorphy2\n",
        "\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "words = [j for i in train.w_cl.tolist() for j in i.split(' ')]\n",
        "to_norm_form = { i: morph.parse(i)[0].normal_form for i in list(set(words))}\n",
        "\n",
        "print('Vocab_size :', len(list(set(to_norm_form.values()))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab_size : 157775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xx_kKDNK80R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(x):\n",
        "  return ' '.join([to_norm_form[i] if i in to_norm_form else i for i in x.split(' ')])\n",
        "\n",
        "train['norm_question'] = train.w_cl.apply(normalize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrPzRd-C4DUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYkIwp_uXmw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train[['main_category', 'example']]\n",
        "train.columns = ['main_category', 'question']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVLpf4jk4DUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_text(text):\n",
        "    \n",
        "    return wordpunct_tokenize(text.lower())\n",
        "    #text.split(' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUFqLXoE4DUh",
        "colab_type": "code",
        "outputId": "df3ad49b-7ead-4fb9-98ec-4ed1227f4608",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word2freq = {}\n",
        "\n",
        "for question in tqdm(train.question):\n",
        "    \n",
        "    words = process_text(question)\n",
        "    \n",
        "    for word in words:\n",
        "        \n",
        "        if word in word2freq:\n",
        "            word2freq[word] += 1\n",
        "        else:\n",
        "            word2freq[word] = 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 666666/666666 [00:05<00:00, 130920.69it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHqixp68Erjo",
        "colab_type": "code",
        "outputId": "2cd5a9cc-2918-423e-df31-4e4b364e5cf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd ../.."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-LtYTtJ41wE",
        "colab_type": "code",
        "outputId": "fb6b2ee5-b9f1-4f16-adb7-66587378c35d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-17 16:47:42--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.22.166, 104.20.6.166, 2606:4700:10::6814:6a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.22.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1306357571 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.ru.300.vec.gz’\n",
            "\n",
            "cc.ru.300.vec.gz    100%[===================>]   1.22G  48.9MB/s    in 25s     \n",
            "\n",
            "2019-12-17 16:48:08 (49.9 MB/s) - ‘cc.ru.300.vec.gz’ saved [1306357571/1306357571]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL6wGL1c6D09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gzip -d cc.ru.300.vec.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOquLkOf4DUk",
        "colab_type": "code",
        "outputId": "9f9d615b-0fa7-4a2b-9f6e-9db684240025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word2index = {'PAD': 0}\n",
        "vectors = []\n",
        "    \n",
        "word2vec_file = open('cc.ru.300.vec')\n",
        "    \n",
        "n_words, embedding_dim = word2vec_file.readline().split()\n",
        "n_words, embedding_dim = int(n_words), int(embedding_dim)\n",
        "\n",
        "# Zero vector for PAD\n",
        "vectors.append(np.zeros((1, embedding_dim)))\n",
        "\n",
        "progress_bar = tqdm(desc='Read word2vec', total=n_words)\n",
        "\n",
        "while True:\n",
        "\n",
        "    line = word2vec_file.readline().strip()\n",
        "\n",
        "    if not line:\n",
        "        break\n",
        "        \n",
        "    current_parts = line.split()\n",
        "\n",
        "    current_word = ' '.join(current_parts[:-embedding_dim])\n",
        "\n",
        "    if current_word in word2freq:\n",
        "\n",
        "        word2index[current_word] = len(word2index)\n",
        "\n",
        "        current_vectors = current_parts[-embedding_dim:]\n",
        "        current_vectors = np.array(list(map(float, current_vectors)))\n",
        "        current_vectors = np.expand_dims(current_vectors, 0)\n",
        "\n",
        "        vectors.append(current_vectors)\n",
        "\n",
        "    progress_bar.update(1)\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "word2vec_file.close()\n",
        "\n",
        "vectors = np.concatenate(vectors)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read word2vec: 100%|██████████| 2000000/2000000 [00:56<00:00, 35713.45it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY8Q7QOi4DUm",
        "colab_type": "code",
        "outputId": "3384df8e-d737-4a36-a068-ad030003d48c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "unk_words = [word for word in word2freq if word not in word2index]\n",
        "unk_counts = [word2freq[word] for word in unk_words]\n",
        "n_unk = sum(unk_counts) * 100 / sum(list(word2freq.values()))\n",
        "\n",
        "sub_sample_unk_words = {word: word2freq[word] for word in unk_words}\n",
        "sorted_unk_words = list(sorted(sub_sample_unk_words, key=lambda x: sub_sample_unk_words[x], reverse=True))\n",
        "\n",
        "print('Мы не знаем {:.2f} % слов в датасете'.format(n_unk))\n",
        "print('Количество неизвестных слов {} из {}, то есть {:.2f} % уникальных слов в словаре'.format(\n",
        "    len(unk_words), len(word2freq), len(unk_words) * 100 / len(word2freq)))\n",
        "print('В среднем каждое встречается {:.2f} раз'.format(np.mean(unk_counts)))\n",
        "print()\n",
        "print('Топ 5 невошедших слов:')\n",
        "\n",
        "for i in range(5):\n",
        "    print(sorted_unk_words[i], 'с количеством вхождениий -', word2freq[sorted_unk_words[i]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Мы не знаем 3.02 % слов в датасете\n",
            "Количество неизвестных слов 107889 из 328896, то есть 32.80 % уникальных слов в словаре\n",
            "В среднем каждое встречается 2.08 раз\n",
            "\n",
            "Топ 5 невошедших слов:\n",
            "??? с количеством вхождениий - 8604\n",
            "!!! с количеством вхождениий - 6976\n",
            "?) с количеством вхождениий - 6613\n",
            "?? с количеством вхождениий - 6327\n",
            "\"? с количеством вхождениий - 4581\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geU38fQA4DUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "class WordData(Dataset):\n",
        "    \n",
        "    def __init__(self, x_data, y_data, word2index, sequence_length=40, pad_token='PAD', verbose=True):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.x_data = []\n",
        "        self.y_data = y_data\n",
        "        \n",
        "        self.word2index = word2index\n",
        "        self.sequence_length = sequence_length\n",
        "        \n",
        "        self.pad_token = pad_token\n",
        "        self.pad_index = self.word2index[self.pad_token]\n",
        "        \n",
        "        self.load(x_data, verbose=verbose)\n",
        "        \n",
        "    @staticmethod\n",
        "    def process_text(text):\n",
        "        \n",
        "        # Место для вашей предобработки\n",
        "    \n",
        "        words = wordpunct_tokenize(text.lower())\n",
        "\n",
        "        return words\n",
        "        \n",
        "    def load(self, data, verbose=True):\n",
        "        \n",
        "        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n",
        "        \n",
        "        for text in data_iterator:\n",
        "            words = self.process_text(text)\n",
        "            indexed_words = self.indexing(words)\n",
        "            self.x_data.append(indexed_words)\n",
        "    \n",
        "    def indexing(self, tokenized_text):\n",
        "\n",
        "        # здесь мы не используем токен UNK, потому что мы мы его специально не учили\n",
        "        # становится непонятно какой же эмбеддинг присвоить неизвестному слову,\n",
        "        # поэтому просто выбрасываем наши неизветсные слова\n",
        "        \n",
        "        ### CODE ###\n",
        "\n",
        "        return [self.word2index[token] for token in tokenized_text if token in self.word2index ]\n",
        "    \n",
        "    def padding(self, sequence):\n",
        "        \n",
        "        # Ограничить длину self.sequence_length\n",
        "        # если длина меньше максимально - западить\n",
        "        \n",
        "        ### CODE ###\n",
        "\n",
        "        if len(sequence) > self.sequence_length:\n",
        "            sequence = sequence[:self.sequence_length]\n",
        "        elif len(sequence) < self.sequence_length:\n",
        "            sequence = sequence + [self.pad_index] * (self.sequence_length - len(sequence))\n",
        "\n",
        "        return sequence\n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.x_data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        x = self.x_data[idx]\n",
        "        if len(x)<=self.sequence_length and len(x)>0:\n",
        "          len_x = len(x)\n",
        "        elif len(x)<=0:\n",
        "          len_x=1\n",
        "        else:\n",
        "          len_x = self.sequence_length\n",
        "        \n",
        "        x = self.padding(x)\n",
        "        x = torch.Tensor(x).long()\n",
        "        \n",
        "        y = self.y_data[idx]\n",
        "        \n",
        "        return x, y, len_x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUVhVBs7ahZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for instance in list(tqdm._instances):\n",
        "    tqdm._decr_instances(instance)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My6dOv7u4DUr",
        "colab_type": "code",
        "outputId": "59cc4151-1937-4d5e-f432-65242e2f50fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x_train, x_validation, y_train, y_validation = train_test_split(train.question, train.main_category, test_size=0.1)\n",
        "\n",
        "train_dataset = WordData(list(x_train), list(y_train), word2index)\n",
        "train_loader = DataLoader(train_dataset, batch_size=128)\n",
        "\n",
        "validation_dataset = WordData(list(x_validation), list(y_validation), word2index)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=128)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data: 100%|██████████| 599999/599999 [00:05<00:00, 104537.64it/s]\n",
            "Loading data: 100%|██████████| 66667/66667 [00:00<00:00, 81502.89it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF81Ll1USSK9",
        "colab_type": "code",
        "outputId": "3a8fafb9-1fb4-4f33-8f0a-b54600499a7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_dataset = WordData(list(test.question), np.zeros((test.shape[0])), word2index)\n",
        "test_loader = DataLoader(test_dataset, batch_size=512 )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data: 100%|██████████| 200000/200000 [00:01<00:00, 130887.08it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g3ng-2OURuJ",
        "colab_type": "code",
        "outputId": "4e3839f1-8a93-420b-b0fc-ff7725b78779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "for x, y, len_x in train_loader:\n",
        "  print(len_x)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 5, 18, 13,  6, 12, 15,  5,  4,  9,  7,  4,  9, 21, 15, 10, 11,  4,  6,\n",
            "        13,  8,  5,  5, 24, 18, 17,  8, 19,  9,  5, 15,  7, 11, 22,  5,  3,  4,\n",
            "         4, 22,  7, 13,  9, 10, 10,  8, 14, 11, 10,  8, 22, 22,  6, 24,  9, 11,\n",
            "        23, 15, 22,  9, 23, 11,  6, 13, 14,  7, 15,  3, 15,  9, 10, 17, 13, 23,\n",
            "         9,  6, 20,  4,  6, 10, 14,  5, 21,  5, 11, 21, 15, 13, 16,  8,  8, 19,\n",
            "         8, 13,  5,  5,  6,  5,  4,  8, 15,  7,  5,  5, 10, 22, 20,  9, 12, 18,\n",
            "        13,  8,  7, 14, 19,  6,  8, 15,  8,  6, 21,  4,  5,  7, 14, 15, 18, 11,\n",
            "        12, 15])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI5l-Egi4DU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_classes = train.main_category.unique().shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASMrV4Fz4DU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from math import sqrt\n",
        "class model_with_att(torch.nn.Module):\n",
        "  def __init__(self, matrix_w, out_GRu_feat, n):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.out_GRu_feat = out_GRu_feat\n",
        "        self.matrix_w = matrix_w\n",
        "\n",
        "        self.out_biGRu = int(self.out_GRu_feat * 2)\n",
        "        self.out_CNN = int(self.out_GRu_feat * 3)\n",
        "        self.n = int(n)\n",
        "\n",
        "        self.num_embeddings, self.embedding_dim = self.matrix_w.shape\n",
        "        self.emb_layer = torch.nn.Embedding(self.num_embeddings, self.embedding_dim)\n",
        "        self.emb_layer.load_state_dict({'weight': torch.tensor(self.matrix_w)})\n",
        "        self.emb_layer.weight.requires_grad = False\n",
        "\n",
        "        self.drop_emb = torch.nn.Dropout(0.15)\n",
        "\n",
        "        self.LSTM = torch.nn.LSTM(self.embedding_dim, out_GRu_feat, num_layers = 2, dropout = 0.25, bidirectional=True, batch_first=True) \n",
        "\n",
        "        #attention\n",
        "        \n",
        "        self.q_proj = torch.nn.Linear(self.out_biGRu, self.out_biGRu)\n",
        "        self.k_proj = torch.nn.Linear(self.out_biGRu, self.out_biGRu)\n",
        "        self.v_proj = torch.nn.Linear(self.out_biGRu, self.out_biGRu)\n",
        "        self.att_soft = torch.nn.Softmax(dim = 2)\n",
        "\n",
        "        self.q_proj1 = torch.nn.Linear(self.out_biGRu, self.out_biGRu)\n",
        "        self.k_proj1 = torch.nn.Linear(self.out_biGRu, self.out_biGRu)\n",
        "        self.v_proj1 = torch.nn.Linear(self.out_biGRu, self.out_biGRu)\n",
        "        \n",
        "        self.permutate = torch.nn.Linear(self.out_biGRu*2, self.out_biGRu)\n",
        "\n",
        "        self.cnn_3gr = torch.nn.Conv1d(in_channels=int(self.out_biGRu) , out_channels=self.out_GRu_feat, kernel_size=3)\n",
        "        self.cnn_4gr = torch.nn.Conv1d(in_channels=int(self.out_biGRu) , out_channels=self.out_GRu_feat, kernel_size=4)\n",
        "        self.cnn_5gr = torch.nn.Conv1d(in_channels=int(self.out_biGRu) , out_channels=self.out_GRu_feat, kernel_size=5)\n",
        "\n",
        "        self.bn1 = torch.nn.BatchNorm1d(self.out_CNN)\n",
        "        \n",
        "        self.linear_1 = torch.nn.Linear(in_features=self.out_CNN, out_features=750)\n",
        "        gl = sqrt(6./(self.out_CNN+750))\n",
        "        self.linear_1.weight.data.uniform_(-gl, gl)\n",
        "\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "        self.drop_out = torch.nn.Dropout(0.1)\n",
        "\n",
        "        self.bn2 = torch.nn.BatchNorm1d(750)\n",
        "\n",
        "        self.linear_2 = torch.nn.Linear(in_features=750, out_features=n)\n",
        "        gl2 = sqrt(6./(750+n))\n",
        "        self.linear_2.weight.data.uniform_(-gl2, gl2)\n",
        "\n",
        "        \n",
        "  def forward(self, x, x_len):\n",
        "      x_emb = self.emb_layer(x)\n",
        "\n",
        "      x_emb = self.drop_emb(x_emb)\n",
        "\n",
        "      x_packed = pack_padded_sequence(x_emb, x_len, batch_first=True, enforce_sorted=False)\n",
        "\n",
        "      x_lstm, _ = self.LSTM(x_packed)\n",
        "\n",
        "      x, _ = pad_packed_sequence(x_lstm, batch_first=True)\n",
        "      \n",
        "      x_q = self.q_proj(x)\n",
        "      x_k = self.k_proj(x)\n",
        "      x_v = self.v_proj(x)\n",
        "\n",
        "      x_q1 = self.q_proj1(x)\n",
        "      x_k1 = self.k_proj1(x)\n",
        "      x_v1 = self.v_proj1(x)\n",
        "\n",
        "      att_scores = torch.bmm(x_q, x_k.transpose(2,1))/self.out_GRu_feat\n",
        "      att_dist = self.att_soft(att_scores)\n",
        "      attention_vectors = torch.bmm(att_dist, x_v)\n",
        "\n",
        "      att_scores1 = torch.bmm(x_q1, x_k1.transpose(2,1))/self.out_GRu_feat\n",
        "      att_dist1 = self.att_soft(att_scores1)\n",
        "      attention_vectors1 = torch.bmm(att_dist1, x_v1)\n",
        "\n",
        "      x_two_at = torch.cat((attention_vectors, attention_vectors1), dim=-1)\n",
        "\n",
        "      x_two_at = self.permutate(x_two_at)\n",
        "      x_gru_s_t = x_two_at.transpose(2,1)\n",
        "\n",
        "      x_cnn3 = self.cnn_3gr(x_gru_s_t)\n",
        "      x_cnn4 = self.cnn_4gr(x_gru_s_t)\n",
        "      x_cnn5 = self.cnn_5gr(x_gru_s_t)\n",
        "\n",
        "      frst, _ =  x_cnn3.max(dim= -1,)\n",
        "      sc, _ = x_cnn4.max(dim= -1,)\n",
        "      thr, _ = x_cnn5.max(dim= -1,)\n",
        "      \n",
        "      px = torch.cat((frst, sc, thr), dim=-1)\n",
        "      \n",
        "      x = self.bn1(px)\n",
        "      x = self.linear_1(x)\n",
        "      x = self.relu(x)\n",
        "      x = self.drop_out(x)\n",
        "      x = self.bn2(x)\n",
        "      x = self.linear_2(x)\n",
        "    \n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCw-uXCY4DU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model_with_att(vectors, 500, n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG0viyxnzynb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from torch.nn.utils.rnn import pad_packed_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ACXSmuDW9Sc",
        "colab_type": "code",
        "outputId": "37d1d81c-a3b5-40c6-d01e-8b890cf9a0bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max(len_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(24)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl0hg6S94DU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    pred = model(x, len_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2Kwq_IJ4DU-",
        "colab_type": "code",
        "outputId": "186c6c57-acd7-480f-b945-8b64ca69244c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_TTeoxv4DVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awaKBMQx-omH",
        "colab_type": "code",
        "outputId": "93bdf987-cced-4c0d-b84c-2f6255fdebc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_with_att(\n",
              "  (emb_layer): Embedding(221008, 300)\n",
              "  (drop_emb): Dropout(p=0.15, inplace=False)\n",
              "  (LSTM): LSTM(300, 500, num_layers=2, batch_first=True, dropout=0.25, bidirectional=True)\n",
              "  (q_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
              "  (k_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
              "  (v_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
              "  (att_soft): Softmax(dim=2)\n",
              "  (q_proj1): Linear(in_features=1000, out_features=1000, bias=True)\n",
              "  (k_proj1): Linear(in_features=1000, out_features=1000, bias=True)\n",
              "  (v_proj1): Linear(in_features=1000, out_features=1000, bias=True)\n",
              "  (cnn_3gr): Conv1d(2000, 500, kernel_size=(3,), stride=(1,))\n",
              "  (cnn_4gr): Conv1d(2000, 500, kernel_size=(4,), stride=(1,))\n",
              "  (cnn_5gr): Conv1d(2000, 500, kernel_size=(5,), stride=(1,))\n",
              "  (bn1): BatchNorm1d(1500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (linear_1): Linear(in_features=1500, out_features=750, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (drop_out): Dropout(p=0.1, inplace=False)\n",
              "  (bn2): BatchNorm1d(750, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (linear_2): Linear(in_features=750, out_features=28, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfOj1ONt4DVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D96CZYuba0jD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlmArnuk4DVF",
        "colab_type": "code",
        "outputId": "b1ec6981-b95f-452b-f560-d1b733822549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "\n",
        "epochs = 10\n",
        "losses = []\n",
        "best_test_loss = 10.\n",
        "\n",
        "test_f1 = []\n",
        "\n",
        "for n_epoch in range(epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "    \n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for x, y, x_len,  in train_loader:\n",
        "\n",
        "    \n",
        "        x_len = x_len.to(device)\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = model(x, x_len)\n",
        "        loss = criterion(pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "        \n",
        "    progress_bar.close()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for x, y, x_len in validation_loader:\n",
        "        \n",
        "        \n",
        "        x = x.to(device)\n",
        "        x_len = x_len.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred = model(x, x_len)\n",
        "\n",
        "            pred = pred.cpu()\n",
        "            y = y.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred, axis=1))\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "        \n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "    \n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "        \n",
        "    # Early stopping:\n",
        "    if mean_test_loss < best_test_loss:\n",
        "        best_test_loss = mean_test_loss\n",
        "    else:\n",
        "        print('Early stopping')\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 599999/599999 [07:39<00:00, 1221.00it/s, train_loss=1.49]\n",
            "Epoch 2:   0%|          | 256/599999 [00:00<06:54, 1445.58it/s, train_loss=1.49]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 1.669, test - 1.437\n",
            "F1 test - 0.586\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 599999/599999 [07:40<00:00, 1209.90it/s, train_loss=1.38]\n",
            "Epoch 3:   0%|          | 256/599999 [00:00<07:00, 1425.05it/s, train_loss=1.38]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 1.425, test - 1.356\n",
            "F1 test - 0.609\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 599999/599999 [07:40<00:00, 1202.82it/s, train_loss=1.31]\n",
            "Epoch 4:   0%|          | 256/599999 [00:00<07:03, 1415.99it/s, train_loss=1.31]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 1.340, test - 1.308\n",
            "F1 test - 0.621\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 599999/599999 [07:39<00:00, 1238.79it/s, train_loss=1.25]\n",
            "Epoch 5:   0%|          | 256/599999 [00:00<06:49, 1465.69it/s, train_loss=1.25]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 1.278, test - 1.281\n",
            "F1 test - 0.629\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5:  15%|█▌        | 90624/599999 [01:08<06:31, 1300.96it/s, train_loss=1.25]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRlpUbq24DVJ",
        "colab_type": "code",
        "outputId": "5831c6b5-e8d6-4ff5-e091-6a485e97a8a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "\n",
        "for x, y, x_len in test_loader:\n",
        "\n",
        "    x = x.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        pred = model(x,x_len)\n",
        "\n",
        "        pred = pred.cpu()\n",
        "        \n",
        "        predictions.append(np.argmax(pred, axis=1))\n",
        "        \n",
        "predictions = np.concatenate(predictions).squeeze()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch 2:   0%|          | 2560/599999 [00:20<05:15, 1895.48it/s, train_loss=1.03]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0owAKef84DVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['main_category'] = predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAynND_r4DVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = test[['index', 'main_category']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKS3EAY84DVR",
        "colab_type": "code",
        "outputId": "9c03366d-e66b-460d-ad16-6caf2633cc26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>main_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  main_category\n",
              "0      0             15\n",
              "1      1             15\n",
              "2      2             25\n",
              "3      3             17\n",
              "4      4             12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb1t2EiI4DVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.to_csv('submission123.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD4v87ZF4DVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('submission123.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfwVw-HmqK2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}