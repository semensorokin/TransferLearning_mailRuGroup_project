{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "elmo_pag_seq_lstm_cnn_attention_fm_mailru.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TosyIB8ZQzH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "colab_type": "code",
        "id": "J3vI12ATXMUc",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import json\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qf-wdNk_Fpx",
        "colab_type": "code",
        "outputId": "e2695435-4dd7-4b4e-cd15-49ce6961a4f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/'My Drive'/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3TJ7pw0OZ-I",
        "colab_type": "code",
        "outputId": "9e292767-9b93-4d20-8f15-f05c5dff8998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%cd gdrive/'My Drive'/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'gdrive/My Drive/'\n",
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uilD6yhv79ct",
        "colab_type": "code",
        "outputId": "8b1d7ddf-320f-4bdb-cb4a-b77576d0d6ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1513347\n",
            "-rw------- 1 root root   19062490 Mar 29  2019  1000_textes.txt\n",
            "drwx------ 2 root root       4096 Sep 30  2018 '6 октября 2018'\n",
            "-rw------- 1 root root     174044 Mar 28  2019  API_NY.GDP.PCAP.PP.CD_DS2_en_csv_v2_10515265.csv\n",
            "drwx------ 2 root root       4096 Jan  7  2019  Basic_stats\n",
            "-rw------- 1 root root      48749 Dec  8 00:41  ClassificationSentimentModelsHSEpract.ipynb\n",
            "drwx------ 2 root root       4096 Oct 28  2018 'Colab Notebooks'\n",
            "-rw------- 1 root root        151 May  3  2019 'Copy of Подход на правилах.gslides'\n",
            "drwx------ 2 root root       4096 Apr 14  2019  corpus\n",
            "drwx------ 2 root root       4096 Dec 15  2018  Deutsch\n",
            "drwx------ 2 root root       4096 Dec 15  2018  Diploms\n",
            "-rw------- 1 root root        151 Dec 20 21:44  DL_project_end2019.gslides\n",
            "drwx------ 2 root root       4096 Dec 15  2018  Docs\n",
            "-rw------- 1 root root       9082 Dec 20 12:44  Elmo_from_DP.ipynb\n",
            "-rw------- 1 root root    1581265 Aug  6 16:31  export.pkl\n",
            "-rw------- 1 root root        151 Feb  2  2019  First_lec_final.gslides\n",
            "-rw------- 1 root root    7849325 Feb  2  2019  First_lec.pptx\n",
            "drwx------ 2 root root       4096 Nov 11  2018  Français\n",
            "drwx------ 2 root root       4096 May 15  2019  FULL_DOCS\n",
            "-rw------- 1 root root        151 Nov 24 15:00  Graph_project.gdoc\n",
            "-rw------- 1 root root        151 Dec 17 08:49  HPC_request.gsheet\n",
            "-rw------- 1 root root        151 Dec  8 00:37  hse_eng_template_presentation.gslides\n",
            "-rw------- 1 root root    1087657 Dec 17  2018  hw4_sorokin_semen.pdf\n",
            "drwx------ 2 root root       4096 Dec 15  2018  HWs\n",
            "-rw------- 1 root root       2026 May 30  2019  leven_distance.ipynb\n",
            "drwx------ 2 root root       4096 May 17  2019  Links_checker\n",
            "-rw------- 1 root root        471 Dec 15 20:43  main_category_mapper.json\n",
            "-rw------- 1 root root        151 May 24  2019  math_shpor.gdoc\n",
            "-rw------- 1 root root        151 Nov  8 19:36  Math_Sorokin_Semen_hw1.gdoc\n",
            "-rw------- 1 root root  327299833 Dec 20 15:55  model.pkl\n",
            "-rw------- 1 root root   29350476 Apr  4  2019  model.pt\n",
            "drwx------ 2 root root       4096 Apr 10  2019  models\n",
            "-rw------- 1 root root        452 Sep 20 16:59  NetworkX_tutorial.ipynb\n",
            "-rw------- 1 root root        151 Mar 15  2019  Nilce.gdoc\n",
            "-rw------- 1 root root      54102 Jun 20  2019  Node_degree.ipynb\n",
            "-rw------- 1 root root        151 Jan 27  2019 'Part 1.gdoc'\n",
            "-rw------- 1 root root        151 Oct 10 16:09 'Plan-And-Write: Towards Better Automatic Storytelling.gslides'\n",
            "drwx------ 2 root root       4096 Mar 27  2019  PRACT\n",
            "drwx------ 2 root root       4096 Dec 15  2018  Presentations\n",
            "-rw------- 1 root root   33108610 Dec  8 00:46  ProductNameCategory.csv\n",
            "-rw------- 1 root root    3410586 Nov  4 23:20 'Project 1 Ageev.pdf'\n",
            "drwx------ 2 root root       4096 Nov 13 14:07  Project_DL_End_2019\n",
            "-rw------- 1 root root 1034790690 Nov 28 13:06  Ques_answ_merged.csv\n",
            "-rw------- 1 root root      14106 May 12  2019  Rekomendatelnoe_pismo.docx\n",
            "-rw------- 1 root root        151 May 12  2019  Rekomendatelnoe_pismo.gdoc\n",
            "drwx------ 2 root root       4096 Dec 15  2018  resume\n",
            "-rw------- 1 root root        151 Nov  4 23:21  ru.gslides\n",
            "dr-x------ 2 root root       4096 May  8  2018 'Russian Language Model'\n",
            "-rw------- 1 root root    8940448 Oct  7 13:12  scoring_set.csv\n",
            "-rw------- 1 root root        202 Mar 27  2019  SemenSorokin\n",
            "-rw------- 1 root root      78372 Jun  1  2019  sentiment_vector.ipynb\n",
            "-rw------- 1 root root        151 Dec 13 11:32  SNAReadingClub.gslides\n",
            "-rw------- 1 root root      42464 Dec 21  2018  Sorokin_Ru_Fr_Hi.ipynb\n",
            "-rw------- 1 root root    2057647 Nov  4 23:56  SorokinSemenProject1.pptx\n",
            "-rw------- 1 root root    1802606 Dec 15 20:40  submission123.csv\n",
            "-rw------- 1 root root    1797863 Nov 30 00:04  submission.csv\n",
            "-rw------- 1 root root   20878219 Apr 18  2019  tagged_data.xlsx\n",
            "-rw------- 1 root root   22965443 Dec 17 17:51  test.csv\n",
            "-rw------- 1 root root    3463506 Feb 15  2019  Text_class_17-02.zip\n",
            "-rw------- 1 root root   27081655 Dec 15 20:43  train.csv.zip\n",
            "-rw------- 1 root root        269 Dec 15 08:45  Untitled\n",
            "-rw------- 1 root root        151 Mar 30  2019 'Untitled document (1).gdoc'\n",
            "-rw------- 1 root root        151 Jun  6  2019 'Untitled document.gdoc'\n",
            "-rw------- 1 root root        151 Nov  4 23:21 'Untitled presentation.gslides'\n",
            "-rw------- 1 root root        151 Oct 31 08:10 'Untitled spreadsheet.gsheet'\n",
            "drwx------ 2 root root       4096 May 11  2019 ' VGS'\n",
            "-rw------- 1 root root       4591 Jun 20  2019  word_compatibility.txt\n",
            "-rw------- 1 root root        151 Dec  8 00:54 'Аннотация курса Коспьютерная лингвистика.gdoc'\n",
            "-rw------- 1 root root        151 Sep 17 16:43  веб-дев.gdoc\n",
            "drwx------ 2 root root       4096 Mar  4  2019  Военка\n",
            "-rw------- 1 root root        151 Dec  8 08:34 'Второй квиз DL.gform'\n",
            "-rw------- 1 root root        151 Jun 10  2019  география.gslides\n",
            "drwx------ 2 root root       4096 Jul 31 09:56  дашафото\n",
            "-rw------- 1 root root      14401 Feb 25  2019  дз2_до15.02.xlsx\n",
            "drwx------ 2 root root       4096 Jul 13 10:28  дипломы\n",
            "-rw------- 1 root root        151 May  6  2019 'Домашнее Задание Сорокин Семен.gdoc'\n",
            "-rw------- 1 root root        151 May 20  2019 'Занятия в АйййййййВышке.gdoc'\n",
            "-rw------- 1 root root    2349860 May 12  2019  ИИ.pptx\n",
            "-rw------- 1 root root        151 May 11  2019 'Наивный байес.gslides'\n",
            "-rw------- 1 root root        151 Jun 28 08:00 'Новый документ.gdoc'\n",
            "-rw------- 1 root root        151 Mar 17  2019 'общая таблица.gsheet'\n",
            "-rw------- 1 root root        151 Mar 17  2019  Общее-3.gsheet\n",
            "-rw------- 1 root root        151 Mar 17  2019  Общее.gsheet\n",
            "-rw------- 1 root root        151 May 16  2019 'Описание графиков.gdoc'\n",
            "-rw------- 1 root root        151 Oct 29 09:12 'Первый квиз DL.gform'\n",
            "-rw------- 1 root root      32768 Mar  7  2019 'Письмо по выплате Бланк АО _1.doc'\n",
            "-rw------- 1 root root        151 Mar  7  2019 'Письмо по выплате Бланк АО _1.gdoc'\n",
            "-rw------- 1 root root        151 Apr 14  2019 'план машинный перевод.gdoc'\n",
            "-rw------- 1 root root        151 May 12  2019 'Подход на правилах.gslides'\n",
            "-rw------- 1 root root        151 Dec 16 10:08 'Проект Transfer-learning for Mail.gdoc'\n",
            "-rw------- 1 root root        151 Sep 20 08:58 'Ресурсы проекта Predictability.gdoc'\n",
            "-rw------- 1 root root      29042 Dec 27  2018  Синицына_Дарья_АКТ.docx\n",
            "-rw------- 1 root root      32889 Dec 27  2018  Синицына_Дарья_Задание.docx\n",
            "-rw------- 1 root root      42496 Feb  1  2019  служебка_кружок2018.doc\n",
            "-rw------- 1 root root        151 Feb  1  2019 'СлужЗап03022019 (1).gdoc'\n",
            "-rw------- 1 root root       9824 Feb 14  2019  СлужЗап03022019.docx\n",
            "-rw------- 1 root root        151 Feb 14  2019  СлужЗап03022019.gdoc\n",
            "-rw------- 1 root root        151 Jan 12  2019  Сорокин_Семен_АКТ.gdoc\n",
            "-rw------- 1 root root        151 Jan 12  2019  Сорокин_Семен_Задание.gdoc\n",
            "-rw------- 1 root root      12486 Feb  1  2019 'Списки_Что умеет искусственный интеллект.docx'\n",
            "-rw------- 1 root root        151 Feb  1  2019 'Списки_Что умеет искусственный интеллект.gdoc'\n",
            "drwx------ 2 root root       4096 Apr 24  2018  Тсп-фото\n",
            "drwx------ 2 root root       4096 Dec 21  2018 'учебный ассистент'\n",
            "-rw------- 1 root root      55562 Mar  6  2019 'Форма представления коллегам новая.docx'\n",
            "-rw------- 1 root root        151 Mar  6  2019 'Форма представления коллегам новая.gdoc'\n",
            "drwx------ 2 root root       4096 Jun 18  2018  Фото\n",
            "-rw------- 1 root root        151 Apr 21  2019 'Шаблон Удетей (1) (1).gslides'\n",
            "-rw------- 1 root root        151 Apr 21  2019 'Шаблон Удетей (1).gslides'\n",
            "-rw------- 1 root root        151 Jan 31  2019 'Шаблон Удетей.gslides'\n",
            "-rw------- 1 root root        151 Jan  5  2019 'Экзамен по французскому языку Кристинкин.gdoc'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcxfDb56WFdk",
        "colab_type": "code",
        "outputId": "2775dbea-df9a-4c87-b1c1-dba167a78d7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train = pd.read_csv('Ques_answ_merged.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning:\n",
            "\n",
            "Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZxUy7j38MDD",
        "colab_type": "code",
        "outputId": "a7ad1c2f-00b8-445c-f955-7b9cac9ae401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>main_category</th>\n",
              "      <th>sub_category</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>Законно ли изменение количества дней листа нет...</td>\n",
              "      <td>Ничего писать не нужно, разве что директору жа...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>Законно ли изменение количества дней листа нет...</td>\n",
              "      <td>И вы хотите ссориться с работодателем из-за 1 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>Законно ли изменение количества дней листа нет...</td>\n",
              "      <td>Чушь спрашиваете, 1 день больше 1 день меньше,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>Законно ли изменение количества дней листа нет...</td>\n",
              "      <td>Что значит переносить не собираются? Куда они ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>Законно ли изменение количества дней листа нет...</td>\n",
              "      <td>В БЛ четко указаны даты ОБиР - с такого-то по ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Unnamed: 0  ...                                             answer\n",
              "0          0  ...  Ничего писать не нужно, разве что директору жа...\n",
              "1          1  ...  И вы хотите ссориться с работодателем из-за 1 ...\n",
              "2          2  ...  Чушь спрашиваете, 1 день больше 1 день меньше,...\n",
              "3          3  ...  Что значит переносить не собираются? Куда они ...\n",
              "4          4  ...  В БЛ четко указаны даты ОБиР - с такого-то по ...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lo5EMl-8gsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train[train.main_category.notna()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ANDja8E8Vzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.main_category = train.main_category.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WApgmFYk9gTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answers = train[['main_category', 'answer']].drop_duplicates()\n",
        "answers.columns = ['main_category', 'question']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiGXP2Ol8oLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.concat([train[['main_category', 'question']].drop_duplicates(),answers])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmff-Z329U13",
        "colab_type": "code",
        "outputId": "14ad7b63-01f8-451f-99f8-68d0cacf8528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3721957, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFFs9bLj92Gb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.question = train.question.astype(str)\n",
        "train['lenn'] = train.question.apply(len)\n",
        "train_longer10 = train[(train.lenn>10)&(train.lenn<400)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93NmK8p3-iP8",
        "colab_type": "code",
        "outputId": "784e4a7c-d278-4233-d885-bfc6481b7f2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(train_longer10.lenn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1487952.,  870984.,  467224.,  198369.,  124891.,   88510.,\n",
              "          62673.,   47263.,   35553.,   27091.]),\n",
              " array([ 11. ,  49.8,  88.6, 127.4, 166.2, 205. , 243.8, 282.6, 321.4,\n",
              "        360.2, 399. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAD4CAYAAADCb7BPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEElSFwNEktTFAJEkdTFAJEld/j/urYaRRJl88QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdcgvbvY-KUa",
        "colab_type": "code",
        "outputId": "16fdd81e-f623-4792-80b8-4aa47f88345f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_longer10.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>main_category</th>\n",
              "      <th>question</th>\n",
              "      <th>lenn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3158904</th>\n",
              "      <td>5</td>\n",
              "      <td>в газету подай а лучше - во все.</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3158906</th>\n",
              "      <td>4</td>\n",
              "      <td>Ты инвалид детства?Пенсия на каком основании?</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3158907</th>\n",
              "      <td>4</td>\n",
              "      <td>Дадут, ровно за 5 дней февраля. хочешт получат...</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3158908</th>\n",
              "      <td>6</td>\n",
              "      <td>Материально то может им и хорошо...но морально...</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3158909</th>\n",
              "      <td>6</td>\n",
              "      <td>у тя жена молодая и красивая?кидай фотку, так ...</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         main_category                                           question  lenn\n",
              "3158904              5                   в газету подай а лучше - во все.    32\n",
              "3158906              4      Ты инвалид детства?Пенсия на каком основании?    45\n",
              "3158907              4  Дадут, ровно за 5 дней февраля. хочешт получат...   101\n",
              "3158908              6  Материально то может им и хорошо...но морально...    57\n",
              "3158909              6  у тя жена молодая и красивая?кидай фотку, так ...   131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNAUuVd7Q5JI",
        "colab_type": "code",
        "outputId": "1a4b946d-1c2e-4f5f-c4b7-55d72b176dc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%time\n",
        "from zipfile import ZipFile\n",
        "\n",
        "downloaded_train = drive.CreateFile({'id':'10qtOKBsGFQlZ6YzQxV30uHT7truULE1E'}) \n",
        "downloaded_train.GetContentFile('train.csv.zip')\n",
        "\n",
        "with ZipFile('train.csv.zip', 'r') as zipObj:\n",
        "   zipObj.extractall()\n",
        "\n",
        "down_main_cat_map = drive.CreateFile({'id': '1l70MFuRBb7IgaVn6hrx0_X3lU0_q0B7C'}) \n",
        "down_main_cat_map.GetContentFile('main_category_mapper.json')\n",
        "\n",
        "downloaded_unsupervised = drive.CreateFile({'id':'1vTeZFDl4ugkRv_6mUCl7gJk8DMnE8ECB'}) \n",
        "downloaded_unsupervised.GetContentFile('unsupervised.csv.zip')\n",
        "\n",
        "with ZipFile('unsupervised.csv.zip', 'r') as zipObj:\n",
        "   zipObj.extractall()\n",
        "\n",
        "down_sub_cat_map = drive.CreateFile({'id': '1SJhd1yLU2V6eKGKI_R7Gw0ybGC9RaxJu'}) \n",
        "down_sub_cat_map.GetContentFile('sub_category_mapper.json')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
            "Wall time: 5.72 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "8VcdFVSGHxHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import json\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jXnIZ7SaHxHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMnIDWL_4gMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded_sub = drive.CreateFile({'id':'1QqoCIhAJlMxW5_TSaNnOUU08civyHWOP'}) \n",
        "downloaded_sub.GetContentFile('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlJwLkUeYOr2",
        "colab_type": "code",
        "outputId": "f7d63cd0-09f2-4e43-9f0c-50d3eb0bab2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test = pd.read_csv('test.csv')\n",
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Подскажите сайт российский, вещи заказывать: )...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Как заказать Рикардо Милоса в Москве?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Пустят ли меня в Израиль, если я работаю в ОАЭ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>почему о наличии пальмового масла и консервато...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Вот во всех бедах России винят правительство.....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                                           question\n",
              "0      0  Подскажите сайт российский, вещи заказывать: )...\n",
              "1      1              Как заказать Рикардо Милоса в Москве?\n",
              "2      2    Пустят ли меня в Израиль, если я работаю в ОАЭ?\n",
              "3      3  почему о наличии пальмового масла и консервато...\n",
              "4      4  Вот во всех бедах России винят правительство....."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z95k9xPSCj2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def filter_ru_en_words(x):\n",
        "  x = ' '.join(re.findall('[a-zа-яё0-9]+', x.lower()))\n",
        "  x = re.sub('[0-9]+', ' число ', x)\n",
        "  x = re.sub('ё', 'е', x)\n",
        "  x = re.sub('\\s+', ' ', x)\n",
        "  return x\n",
        "train['w_cl'] = train.question.apply(filter_ru_en_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozJg0-ZhKN9t",
        "colab_type": "code",
        "outputId": "43c3e6e6-bb41-49db-d4b3-f8d42d3ffd04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install pymorphy2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.6/dist-packages (0.8)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (2.4.393442.3710985)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oABU1BZ1KVxa",
        "colab_type": "code",
        "outputId": "12f68efc-315e-457a-c42d-90a18cfc3b4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pymorphy2\n",
        "\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "words = [j for i in train.w_cl.tolist() for j in i.split(' ')]\n",
        "to_norm_form = { i: morph.parse(i)[0].normal_form for i in list(set(words))}\n",
        "\n",
        "print('Vocab_size :', len(list(set(to_norm_form.values()))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab_size : 157775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xx_kKDNK80R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(x):\n",
        "  return ' '.join([to_norm_form[i] if i in to_norm_form else i for i in x.split(' ')])\n",
        "\n",
        "train['norm_question'] = train.w_cl.apply(normalize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrPzRd-C4DUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYkIwp_uXmw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train[['main_category', 'example']]\n",
        "train.columns = ['main_category', 'question']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVLpf4jk4DUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_text(text):\n",
        "    \n",
        "    return wordpunct_tokenize(text.lower())\n",
        "    #text.split(' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUFqLXoE4DUh",
        "colab_type": "code",
        "outputId": "46445da6-b5e7-4130-ad38-24f00c69f8d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word2freq = {}\n",
        "\n",
        "for question in tqdm(train.question):\n",
        "    \n",
        "    words = process_text(question)\n",
        "    \n",
        "    for word in words:\n",
        "        \n",
        "        if word in word2freq:\n",
        "            word2freq[word] += 1\n",
        "        else:\n",
        "            word2freq[word] = 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 666666/666666 [00:05<00:00, 132432.03it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHqixp68Erjo",
        "colab_type": "code",
        "outputId": "ba7b98e7-6215-4be3-9334-804309afba9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd ../.."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-LtYTtJ41wE",
        "colab_type": "code",
        "outputId": "79b8daa7-79bb-4aae-fd92-942424474e3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget http://vectors.nlpl.eu/repository/11/195.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-20 22:36:13--  http://vectors.nlpl.eu/repository/11/195.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.225\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.225|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 206977021 (197M) [application/zip]\n",
            "Saving to: ‘195.zip’\n",
            "\n",
            "195.zip             100%[===================>] 197.39M   518KB/s    in 13m 46s \n",
            "\n",
            "2019-12-20 22:49:59 (245 KB/s) - ‘195.zip’ saved [206977021/206977021]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL6wGL1c6D09",
        "colab_type": "code",
        "outputId": "a0db777d-d363-4ae9-cf9f-b5a472c1a388",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!unzip 195.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  195.zip\n",
            "  inflating: meta.json               \n",
            "  inflating: model.hdf5              \n",
            "  inflating: options.json            \n",
            "  inflating: README                  \n",
            "  inflating: vocab.txt               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlOBTQYfIFt8",
        "colab_type": "code",
        "outputId": "cb7cb8c6-401c-4cac-a629-b1b981fdebc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install allennlp"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting allennlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/bb/041115d8bad1447080e5d1e30097c95e4b66e36074277afce8620a61cee3/allennlp-0.9.0-py3-none-any.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.17.4)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp) (4.28.1)\n",
            "Collecting tensorboardX>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/5c/e918d9f190baab8d55bad52840d8091dd5114cc99f03eaa6d72d404503cc/tensorboardX-1.9-py2.py3-none-any.whl (190kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 59.0MB/s \n",
            "\u001b[?25hCollecting responses>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/3e/0c/940781dd49710f4b1f0650c450c9fd8491db0e1bffd99ebc36355607f96d/responses-0.10.9-py2.py3-none-any.whl\n",
            "Collecting jsonnet>=0.10.0; sys_platform != \"win32\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/a6/e69e38f1f259fcf8532d8bd2c4bc88764f42d7b35a41423a7f4b035cc5ce/jsonnet-0.14.0.tar.gz (253kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 47.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlparse>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.3.0)\n",
            "Requirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.1)\n",
            "Collecting word2number>=1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n",
            "Collecting jsonpickle\n",
            "  Downloading https://files.pythonhosted.org/packages/07/07/c157520a3ebd166c8c24c6ae0ecae7c3968eb4653ff0e5af369bb82f004d/jsonpickle-1.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.21.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.8.0)\n",
            "Collecting flaky\n",
            "  Downloading https://files.pythonhosted.org/packages/fe/12/0f169abf1aa07c7edef4855cca53703d2e6b7ecbded7829588ac7e7e3424/flaky-3.6.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.10.40)\n",
            "Collecting overrides\n",
            "  Downloading https://files.pythonhosted.org/packages/86/7a/532fc167366797f66c732549490dcf13243077f15446115f3c0ad17e56b8/overrides-2.6.tar.gz\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.4)\n",
            "Collecting conllu==1.3.1\n",
            "  Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 33.4MB/s \n",
            "\u001b[?25hCollecting parsimonious>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/fc/067a3f89869a41009e1a7cdfb14725f8ddd246f30f63c645e8ef8a1c56f4/parsimonious-0.8.1.tar.gz (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.8MB/s \n",
            "\u001b[?25hCollecting pytorch-transformers==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/89/ad0d6bb932d0a51793eaabcf1617a36ff530dc9ab9e38f765a35dc293306/pytorch_transformers-1.1.0-py3-none-any.whl (158kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 63.0MB/s \n",
            "\u001b[?25hCollecting numpydoc>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/f3/7cfe4c616e4b9fe05540256cc9c6661c052c8a4cec2915732793b36e1843/numpydoc-0.9.1.tar.gz\n",
            "Collecting flask-cors>=3.0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/78/38/e68b11daa5d613e3a91e4bf3da76c94ac9ee0d9cd515af9c1ab80d36f709/Flask_Cors-3.0.8-py2.py3-none-any.whl\n",
            "Requirement already satisfied: gevent>=1.3.6 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.0)\n",
            "Requirement already satisfied: spacy<2.2,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.1.9)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.3.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.3.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2018.9)\n",
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ca/2d9a5030eaf1bcd925dab392762b9709a7ad4bd486a90599d93cd79cb188/ftfy-5.6.tar.gz (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.5.3)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.1.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.2.5)\n",
            "Collecting pytorch-pretrained-bert>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 55.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (3.10.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (2.10.3)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (0.16.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (7.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp) (0.14.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.40 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (1.13.40)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.8.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (19.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (42.0.2)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (8.0.2)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.3.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.1.0->allennlp) (2019.12.9)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 44.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp) (1.8.5)\n",
            "Requirement already satisfied: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.6/dist-packages (from gevent>=1.3.6->allennlp) (0.4.15)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (2.0.1)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.9.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (2.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.4.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.2.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (1.0.2)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (7.0.8)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.2.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->allennlp) (0.1.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.6.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.4.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2.8)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask>=1.0.2->allennlp) (1.1.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->allennlp) (0.15.2)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.1.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.0.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.7.0)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.1.3)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.1.2)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (0.7.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (19.2)\n",
            "Building wheels for collected packages: jsonnet, word2number, overrides, parsimonious, numpydoc, ftfy\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.14.0-cp36-cp36m-linux_x86_64.whl size=3320387 sha256=a3fcb32b383a7b022dd55cd8730298f3f5ebc611eac5b3528fc2ef4c488e29c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/b7/83/985f0f758fbb34f14989a0fab86d18890d1cc5ae12f26967bc\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-cp36-none-any.whl size=5588 sha256=1818cd7aba7e491aaceaac5fd6baf00112700d03c45070e8f94ba979793e1cf5\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.6-cp36-none-any.whl size=5523 sha256=da76a2808ecfd3315f06d5057698625257c1beae59274cd2ecba8c506095305c\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/86/49/c413319bcff638bdc13462c063c84d68e294d84514170c3744\n",
            "  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parsimonious: filename=parsimonious-0.8.1-cp36-none-any.whl size=42709 sha256=064a7aef6e67593b98aa83fc90791331140bc87b0b8578a9bffe36ded80380d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/8d/e7/a0e74217da5caeb3c1c7689639b6d28ddbf9985b840bc96a9a\n",
            "  Building wheel for numpydoc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for numpydoc: filename=numpydoc-0.9.1-cp36-none-any.whl size=31872 sha256=45e51e3ca67d9abc52c4577a7936506995d29fe4eebfca74164bb732de8cb354\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/30/d1/92a39ba40f21cb70e53f8af96eb98f002a781843c065406500\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.6-cp36-none-any.whl size=44553 sha256=dddae87011098f23b9c58535cd4cbe680f9ac39f5cbffa3f701c4968c527aa91\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/34/ce/cbb38d71543c408de56f3c5e26ce8ba495a0fa5a28eaaf1046\n",
            "Successfully built jsonnet word2number overrides parsimonious numpydoc ftfy\n",
            "Installing collected packages: tensorboardX, responses, jsonnet, word2number, jsonpickle, flaky, overrides, conllu, unidecode, parsimonious, sentencepiece, pytorch-transformers, numpydoc, flask-cors, ftfy, pytorch-pretrained-bert, allennlp\n",
            "Successfully installed allennlp-0.9.0 conllu-1.3.1 flaky-3.6.1 flask-cors-3.0.8 ftfy-5.6 jsonnet-0.14.0 jsonpickle-1.2 numpydoc-0.9.1 overrides-2.6 parsimonious-0.8.1 pytorch-pretrained-bert-0.6.2 pytorch-transformers-1.1.0 responses-0.10.9 sentencepiece-0.1.85 tensorboardX-1.9 unidecode-1.1.1 word2number-1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtlG_8M7pX3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!export CUDA_VISIBLE_DEVICES=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1dgu-tmr_WB",
        "colab_type": "code",
        "outputId": "f6afed31-7f77-4fa5-9c38-9053d224bc76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!cat meta.json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"algorithm\": {\n",
            "        \"command\": null,\n",
            "        \"id\": 6,\n",
            "        \"name\": \"Embeddings from Language Models (ELMo)\",\n",
            "        \"url\": \"https://allennlp.org/elmo\",\n",
            "        \"version\": null\n",
            "    },\n",
            "    \"contents\": [\n",
            "        {\n",
            "            \"filename\": \"options.json\",\n",
            "            \"format\": \"json\"\n",
            "        },\n",
            "        {\n",
            "            \"filename\": \"meta.json\",\n",
            "            \"format\": \"json\"\n",
            "        },\n",
            "        {\n",
            "            \"filename\": \"model.hdf5\",\n",
            "            \"format\": \"data\"\n",
            "        },\n",
            "        {\n",
            "            \"filename\": \"vocab.txt\",\n",
            "            \"format\": \"text\"\n",
            "        }\n",
            "    ],\n",
            "    \"corpus\": [\n",
            "        {\n",
            "            \"NER\": false,\n",
            "            \"case preserved\": true,\n",
            "            \"description\": \"Russian Wikipedia dump of December 2018\",\n",
            "            \"id\": 103,\n",
            "            \"language\": \"rus\",\n",
            "            \"lemmatized\": false,\n",
            "            \"public\": true,\n",
            "            \"stop words removal\": null,\n",
            "            \"tagger\": null,\n",
            "            \"tagset\": null,\n",
            "            \"tokens\": 654914888,\n",
            "            \"tool\": \"https://github.com/RaRe-Technologies/gensim/blob/master/gensim/scripts/segment_wiki.py\",\n",
            "            \"url\": \"https://dumps.wikimedia.org/\"\n",
            "        },\n",
            "        {\n",
            "            \"NER\": false,\n",
            "            \"case preserved\": true,\n",
            "            \"description\": \"Russian National Corpus\",\n",
            "            \"id\": 104,\n",
            "            \"language\": \"rus\",\n",
            "            \"lemmatized\": false,\n",
            "            \"public\": false,\n",
            "            \"stop words removal\": null,\n",
            "            \"tagger\": null,\n",
            "            \"tagset\": null,\n",
            "            \"tokens\": 334162199,\n",
            "            \"url\": \"http://ruscorpora.ru/\"\n",
            "        }\n",
            "    ],\n",
            "    \"dimensions\": 1024,\n",
            "    \"documentation\": \"https://github.com/ltgoslo/simple_elmo\",\n",
            "    \"external_id\": \"ruwikiruscorpora_tokens_elmo_1024_2019\",\n",
            "    \"id\": 195,\n",
            "    \"iterations\": 3,\n",
            "    \"maintainers\": [\n",
            "        {\n",
            "            \"email\": \"andreku@ifi.uio.no\",\n",
            "            \"name\": \"Andrey Kutuzov\"\n",
            "        }\n",
            "    ]\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45Em3vGnILkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
        "\n",
        "options_file = \"options.json\"\n",
        "weight_file = \"model.hdf5\"\n",
        "\n",
        "# Compute two different representation for each token.\n",
        "# Each representation is a linear weighted combination for the\n",
        "# 3 layers in ELMo (i.e., charcnn, the outputs of the two BiLSTM))\n",
        "elmo = Elmo(options_file, weight_file, 1)\n",
        "\n",
        "# use batch_to_ids to convert sentences to character ids\n",
        "sentences = [['я', 'тут', '.']]\n",
        "character_ids = batch_to_ids(sentences)\n",
        "\n",
        "embeddings = elmo(character_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOquLkOf4DUk",
        "colab_type": "code",
        "outputId": "e09a9fd9-2186-45d9-a51e-ab7043ff72f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word2index = {'PAD': 0}\n",
        "vectors = []\n",
        "    \n",
        "word2vec_file = open('cc.ru.300.vec')\n",
        "    \n",
        "n_words, embedding_dim = word2vec_file.readline().split()\n",
        "n_words, embedding_dim = int(n_words), int(embedding_dim)\n",
        "\n",
        "# Zero vector for PAD\n",
        "vectors.append(np.zeros((1, embedding_dim)))\n",
        "\n",
        "progress_bar = tqdm(desc='Read word2vec', total=n_words)\n",
        "\n",
        "while True:\n",
        "\n",
        "    line = word2vec_file.readline().strip()\n",
        "\n",
        "    if not line:\n",
        "        break\n",
        "        \n",
        "    current_parts = line.split()\n",
        "\n",
        "    current_word = ' '.join(current_parts[:-embedding_dim])\n",
        "\n",
        "    if current_word in word2freq:\n",
        "\n",
        "        word2index[current_word] = len(word2index)\n",
        "\n",
        "        current_vectors = current_parts[-embedding_dim:]\n",
        "        current_vectors = np.array(list(map(float, current_vectors)))\n",
        "        current_vectors = np.expand_dims(current_vectors, 0)\n",
        "\n",
        "        vectors.append(current_vectors)\n",
        "\n",
        "    progress_bar.update(1)\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "word2vec_file.close()\n",
        "\n",
        "vectors = np.concatenate(vectors)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read word2vec: 100%|██████████| 2000000/2000000 [01:20<00:00, 24918.58it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY8Q7QOi4DUm",
        "colab_type": "code",
        "outputId": "9c49fcb0-3277-49f5-abb5-66474642ef1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "unk_words = [word for word in word2freq if word not in word2index]\n",
        "unk_counts = [word2freq[word] for word in unk_words]\n",
        "n_unk = sum(unk_counts) * 100 / sum(list(word2freq.values()))\n",
        "\n",
        "sub_sample_unk_words = {word: word2freq[word] for word in unk_words}\n",
        "sorted_unk_words = list(sorted(sub_sample_unk_words, key=lambda x: sub_sample_unk_words[x], reverse=True))\n",
        "\n",
        "print('Мы не знаем {:.2f} % слов в датасете'.format(n_unk))\n",
        "print('Количество неизвестных слов {} из {}, то есть {:.2f} % уникальных слов в словаре'.format(\n",
        "    len(unk_words), len(word2freq), len(unk_words) * 100 / len(word2freq)))\n",
        "print('В среднем каждое встречается {:.2f} раз'.format(np.mean(unk_counts)))\n",
        "print()\n",
        "print('Топ 5 невошедших слов:')\n",
        "\n",
        "for i in range(5):\n",
        "    print(sorted_unk_words[i], 'с количеством вхождениий -', word2freq[sorted_unk_words[i]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Мы не знаем 3.67 % слов в датасете\n",
            "Количество неизвестных слов 1087038 из 1605861, то есть 67.69 % уникальных слов в словаре\n",
            "В среднем каждое встречается 2.62 раз\n",
            "\n",
            "Топ 5 невошедших слов:\n",
            ":// с количеством вхождениий - 160002\n",
            "). с количеством вхождениий - 65281\n",
            ")) с количеством вхождениий - 54777\n",
            "), с количеством вхождениий - 46012\n",
            "))) с количеством вхождениий - 45007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obKlENlg_5v0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2f = [(k, v) for k, v in sorted(word2freq.items(), key=lambda item: item[1], reverse=True)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-wjrGqEAYfg",
        "colab_type": "code",
        "outputId": "a216c731-1b21-43dc-9319-317127c00daf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "w2f[:25]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('?', 403588),\n",
              " (',', 262851),\n",
              " ('в', 206664),\n",
              " ('.', 175824),\n",
              " ('на', 132762),\n",
              " ('как', 113141),\n",
              " ('и', 110618),\n",
              " ('что', 105986),\n",
              " ('не', 85736),\n",
              " ('ли', 81340),\n",
              " ('с', 78230),\n",
              " ('-', 74052),\n",
              " ('можно', 45264),\n",
              " ('по', 45076),\n",
              " ('или', 43236),\n",
              " ('если', 42678),\n",
              " ('а', 41606),\n",
              " ('(', 37978),\n",
              " ('у', 37612),\n",
              " ('почему', 37158),\n",
              " ('\"', 37054),\n",
              " ('для', 36844),\n",
              " ('это', 34831),\n",
              " ('помогите', 34358),\n",
              " (')', 33495)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpcDoVjvopN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train[350000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDy5hmXirIiT",
        "colab_type": "code",
        "outputId": "3d1dc9e3-3af9-4338-d26a-77f991e063c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sequence = ['f', 'f', 'f', 'f', 'f', 'f', 'f']+['f', 'f', 'f', 'f', 'f', 'f', 'f']+['f', 'f', 'f', 'f', 'f', 'f', 'f']+['f', 'f', 'f', 'f', 'f', 'f', 'f']+['f', 'f', 'f', 'f', 'f', 'f', 'f']+['f', 'f', 'f', 'f', 'f', 'f', 'f']\n",
        "s = (32 if len(sequence)>=32 else len(sequence))\n",
        "s"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geU38fQA4DUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "class WordData(Dataset):\n",
        "    \n",
        "    def __init__(self, x_data, y_data, verbose=True):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.x_data = []\n",
        "        self.y_data = y_data\n",
        "        self.pad_token = 'unk'\n",
        "        self.sequence_length = 32\n",
        "      \n",
        "        \n",
        "        self.load(x_data, verbose=verbose)\n",
        " \n",
        "    def padding(self, sequence):\n",
        "        \n",
        "        # Ограничить длину self.sequence_length\n",
        "        # если длина меньше максимально - западить\n",
        "        \n",
        "        ### CODE ###\n",
        "        s = (self.sequence_length if len(sequence)>=32 else len(sequence))\n",
        "\n",
        "        if len(sequence) > self.sequence_length:\n",
        "            sequence = sequence[:self.sequence_length]\n",
        "\n",
        "        elif len(sequence) < self.sequence_length:\n",
        "            sequence = sequence + [self.pad_token] * (self.sequence_length - len(sequence))\n",
        "\n",
        "        return sequence, s\n",
        "        \n",
        "    @staticmethod\n",
        "    def process_text(text):\n",
        "    \n",
        "        words = wordpunct_tokenize(text.lower())\n",
        "\n",
        "        return words\n",
        "    \n",
        "        \n",
        "    def load(self, data, verbose=True):\n",
        "        \n",
        "        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n",
        "        \n",
        "        for text in data_iterator:\n",
        "            words = self.process_text(text)\n",
        "            seq, s = self.padding(words)\n",
        "            indexed_words = batch_to_ids([seq])\n",
        "            #print(indexed_words.shape)\n",
        "            self.x_data.append((indexed_words, s))\n",
        "            \n",
        "\n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.x_data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        x, s = self.x_data[idx][0], self.x_data[idx][1]\n",
        "      \n",
        "        #x = torch.Tensor(x).long()\n",
        "        \n",
        "        y = self.y_data[idx]\n",
        "        \n",
        "        return x, y, s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUVhVBs7ahZD",
        "colab_type": "code",
        "outputId": "132a0afe-ac74-4ed5-c63f-d642e00af104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for instance in list(tqdm._instances):\n",
        "    tqdm._decr_instances(instance)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My6dOv7u4DUr",
        "colab_type": "code",
        "outputId": "85027d1d-21db-409d-e836-fc459fa001b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x_train, x_validation, y_train, y_validation = train_test_split(train.question, train.main_category, test_size=0.05)\n",
        "\n",
        "train_dataset = WordData(list(x_train), list(y_train))\n",
        "train_loader = DataLoader(train_dataset, batch_size=256,)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data:   3%|▎         | 10317/300832 [00:02<01:14, 3889.35it/s]\n",
            "Loading data: 100%|██████████| 300832/300832 [01:24<00:00, 3579.66it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NntUG8AWWhWE",
        "colab_type": "code",
        "outputId": "15b9d4d9-ac93-43b8-b6dd-b417936b59b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_dataset = WordData(list(x_validation), list(y_validation))\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=512)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data: 100%|██████████| 15834/15834 [00:04<00:00, 3628.11it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF81Ll1USSK9",
        "colab_type": "code",
        "outputId": "49cf1db3-299b-4bae-a0ce-3cebe7916220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_dataset = WordData(list(test.question), np.zeros((test.shape[0])))\n",
        "test_loader = DataLoader(test_dataset, batch_size=512)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data: 100%|██████████| 200000/200000 [00:55<00:00, 3606.20it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g3ng-2OURuJ",
        "colab_type": "code",
        "outputId": "31774d5a-a829-4984-ab29-4995fa5d1231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "for x, y, s in train_loader:\n",
        "  print(x.squeeze(1).shape)\n",
        "  print(elmo(x.squeeze(1))['elmo_representations'][0].shape)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 32, 50])\n",
            "torch.Size([128, 32, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI5l-Egi4DU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_classes = train.main_category.unique().shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASMrV4Fz4DU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from math import sqrt\n",
        "class model_with_att(torch.nn.Module):\n",
        "  def __init__(self, out_GRu_feat, n):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.out_GRu_feat = out_GRu_feat\n",
        "\n",
        "        self.out_biGRu = int(self.out_GRu_feat * 2)\n",
        "        self.out_CNN = int(self.out_GRu_feat * 3)\n",
        "        self.n = int(n)\n",
        "\n",
        "        self.drop_emb = torch.nn.Dropout(0.15)\n",
        "\n",
        "        self.LSTM = torch.nn.LSTM(1024, out_GRu_feat, num_layers = 2, dropout = 0.25, bidirectional=True, batch_first=True) \n",
        "\n",
        "        #attention\n",
        "        \n",
        "        self.q_proj = torch.nn.Linear(self.out_biGRu, self.out_biGRu)\n",
        "        self.k_proj = torch.nn.Linear(self.out_biGRu, self.out_biGRu)\n",
        "        self.v_proj = torch.nn.Linear(self.out_biGRu, self.out_biGRu)\n",
        "        self.att_soft = torch.nn.Softmax(dim = 2)\n",
        "\n",
        "        self.q_proj1 = torch.nn.Linear(self.out_biGRu, self.out_biGRu)\n",
        "        self.k_proj1 = torch.nn.Linear(self.out_biGRu, self.out_biGRu)\n",
        "        self.v_proj1 = torch.nn.Linear(self.out_biGRu, self.out_biGRu)\n",
        "        \n",
        "        self.permutate = torch.nn.Linear(self.out_biGRu*2, self.out_biGRu)\n",
        "\n",
        "        self.cnn_3gr = torch.nn.Conv1d(in_channels=int(self.out_biGRu) , out_channels=self.out_GRu_feat, kernel_size=3)\n",
        "        self.cnn_4gr = torch.nn.Conv1d(in_channels=int(self.out_biGRu) , out_channels=self.out_GRu_feat, kernel_size=4)\n",
        "        self.cnn_5gr = torch.nn.Conv1d(in_channels=int(self.out_biGRu) , out_channels=self.out_GRu_feat, kernel_size=5)\n",
        "\n",
        "        self.bn1 = torch.nn.BatchNorm1d(self.out_CNN)\n",
        "        \n",
        "        self.linear_1 = torch.nn.Linear(in_features=self.out_CNN, out_features=750)\n",
        "        gl = sqrt(6./(self.out_CNN+750))\n",
        "        self.linear_1.weight.data.uniform_(-gl, gl)\n",
        "\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "        self.drop_out = torch.nn.Dropout(0.1)\n",
        "\n",
        "        self.bn2 = torch.nn.BatchNorm1d(750)\n",
        "\n",
        "        self.linear_2 = torch.nn.Linear(in_features=750, out_features=n)\n",
        "        gl2 = sqrt(6./(750+n))\n",
        "        self.linear_2.weight.data.uniform_(-gl2, gl2)\n",
        "\n",
        "        \n",
        "  def forward(self, x, x_len):\n",
        "\n",
        "      x_packed = pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False)\n",
        "\n",
        "      x_lstm, _ = self.LSTM(x_packed)\n",
        "\n",
        "      x, _ = pad_packed_sequence(x_lstm, batch_first=True)\n",
        "      \n",
        "      x_q = self.q_proj(x)\n",
        "      x_k = self.k_proj(x)\n",
        "      x_v = self.v_proj(x)\n",
        "\n",
        "      x_q1 = self.q_proj1(x)\n",
        "      x_k1 = self.k_proj1(x)\n",
        "      x_v1 = self.v_proj1(x)\n",
        "\n",
        "      att_scores = torch.bmm(x_q, x_k.transpose(2,1))/self.out_GRu_feat\n",
        "      att_dist = self.att_soft(att_scores)\n",
        "      attention_vectors = torch.bmm(att_dist, x_v)\n",
        "\n",
        "      att_scores1 = torch.bmm(x_q1, x_k1.transpose(2,1))/self.out_GRu_feat\n",
        "      att_dist1 = self.att_soft(att_scores1)\n",
        "      attention_vectors1 = torch.bmm(att_dist1, x_v1)\n",
        "\n",
        "      x_two_at = torch.cat((attention_vectors, attention_vectors1), dim=-1)\n",
        "\n",
        "      x_two_at = self.permutate(x_two_at)\n",
        "      x_gru_s_t = x_two_at.transpose(2,1)\n",
        "\n",
        "      x_cnn3 = self.cnn_3gr(x_gru_s_t)\n",
        "      x_cnn4 = self.cnn_4gr(x_gru_s_t)\n",
        "      x_cnn5 = self.cnn_5gr(x_gru_s_t)\n",
        "\n",
        "      frst, _ =  x_cnn3.max(dim= -1,)\n",
        "      sc, _ = x_cnn4.max(dim= -1,)\n",
        "      thr, _ = x_cnn5.max(dim= -1,)\n",
        "      \n",
        "      px = torch.cat((frst, sc, thr), dim=-1)\n",
        "      \n",
        "      x = self.bn1(px)\n",
        "      x = self.linear_1(x)\n",
        "      x = self.relu(x)\n",
        "      x = self.drop_out(x)\n",
        "      x = self.bn2(x)\n",
        "      x = self.linear_2(x)\n",
        "    \n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCw-uXCY4DU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model_with_att(500, n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG0viyxnzynb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from torch.nn.utils.rnn import pad_packed_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ACXSmuDW9Sc",
        "colab_type": "code",
        "outputId": "8defc0b3-6a59-4174-c0a9-630cc3da143a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max(len_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl0hg6S94DU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    x = x.squeeze(1)\n",
        "    x = elmo(x.squeeze(1))['elmo_representations'][0]\n",
        "    pred = model(x, s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2Kwq_IJ4DU-",
        "colab_type": "code",
        "outputId": "9115f792-948f-49e9-9d85-d29afcc656b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_TTeoxv4DVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbY-rnHSr4R_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awaKBMQx-omH",
        "colab_type": "code",
        "outputId": "63a65833-66c6-4d84-ffa6-3a255847e0fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_with_att(\n",
              "  (drop_emb): Dropout(p=0.15, inplace=False)\n",
              "  (LSTM): LSTM(1024, 500, num_layers=2, batch_first=True, dropout=0.25, bidirectional=True)\n",
              "  (q_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
              "  (k_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
              "  (v_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
              "  (att_soft): Softmax(dim=2)\n",
              "  (q_proj1): Linear(in_features=1000, out_features=1000, bias=True)\n",
              "  (k_proj1): Linear(in_features=1000, out_features=1000, bias=True)\n",
              "  (v_proj1): Linear(in_features=1000, out_features=1000, bias=True)\n",
              "  (permutate): Linear(in_features=2000, out_features=1000, bias=True)\n",
              "  (cnn_3gr): Conv1d(1000, 500, kernel_size=(3,), stride=(1,))\n",
              "  (cnn_4gr): Conv1d(1000, 500, kernel_size=(4,), stride=(1,))\n",
              "  (cnn_5gr): Conv1d(1000, 500, kernel_size=(5,), stride=(1,))\n",
              "  (bn1): BatchNorm1d(1500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (linear_1): Linear(in_features=1500, out_features=750, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (drop_out): Dropout(p=0.1, inplace=False)\n",
              "  (bn2): BatchNorm1d(750, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (linear_2): Linear(in_features=750, out_features=28, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfOj1ONt4DVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D96CZYuba0jD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6XbkKWJfnkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "elmo = elmo.cpu()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlmArnuk4DVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "\n",
        "epochs = 2\n",
        "losses = []\n",
        "best_test_loss = 10.\n",
        "\n",
        "test_f1 = []\n",
        "\n",
        "for n_epoch in range(epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "    \n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "    \n",
        "    model.train()\n",
        "    i=0\n",
        "    for x, y, x_len in train_loader:\n",
        "        i+=1\n",
        "        if i%50 ==0:\n",
        "          torch.save({\n",
        "              'epoch': n_epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              }, 'model.pkl')\n",
        "\n",
        "        \n",
        "        x = x.squeeze(1)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "          x = elmo(x)['elmo_representations'][0] \n",
        "        \n",
        "        x_len = x_len.to(device)\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "       \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = model(x, x_len)\n",
        "        \n",
        "        loss = criterion(pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "        \n",
        "    progress_bar.close()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for x, y, x_len in validation_loader:\n",
        "        \n",
        "        x = x.squeeze(1)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "          x = elmo(x)['elmo_representations'][0] \n",
        "\n",
        "        x = x.to(device)\n",
        "        x_len = x_len.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred = model(x, x_len)\n",
        "\n",
        "            pred = pred.cpu()\n",
        "            y = y.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred, axis=1))\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "        \n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "    \n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "        \n",
        "    # Early stopping:\n",
        "    if mean_test_loss < best_test_loss:\n",
        "        best_test_loss = mean_test_loss\n",
        "    else:\n",
        "        print('Early stopping')\n",
        "        break "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRI5DTAr_ic5",
        "colab_type": "code",
        "outputId": "5ef4f9ef-3e7b-4c77-eefc-66e7294608b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/'My Drive'/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAZy9WAE_Ia8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save({\n",
        "            'epoch': n_epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            }, 'model.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39_kKgDhBbsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = torch.load('model.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiN6NkuDCF6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTSG4u4cANrz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRlpUbq24DVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "\n",
        "for x, y, x_len in test_loader:\n",
        "    x = x.squeeze(1)\n",
        "        \n",
        "    with torch.no_grad():\n",
        "      x = elmo(x)['elmo_representations'][0] \n",
        "\n",
        "    x = x.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        pred = model(x,x_len)\n",
        "\n",
        "        pred = pred.cpu()\n",
        "        \n",
        "        predictions.append(np.argmax(pred, axis=1))\n",
        "        \n",
        "predictions = np.concatenate(predictions).squeeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0owAKef84DVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['main_category'] = predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAynND_r4DVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = test[['index', 'main_category']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKS3EAY84DVR",
        "colab_type": "code",
        "outputId": "8097dc7d-164a-4a3b-8344-570d720d2ba5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>main_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  main_category\n",
              "0      0              9\n",
              "1      1             15\n",
              "2      2             18\n",
              "3      3             17\n",
              "4      4             12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb1t2EiI4DVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.to_csv('submission123.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD4v87ZF4DVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('submission123.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfwVw-HmqK2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}